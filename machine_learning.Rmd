---
title: "Practical Machine Learning"
author: "Walter Appati"
date: "`r Sys.Date()`"
output: html_document
---

```{r setup, include=FALSE}
library(ggplot2)
library(caret)
knitr::opts_chunk$set(echo = TRUE)
```


### Introduction

Introduction
This project aims to predict the manner in which participants performed barbell lifts, represented by the classe variable. Using the "Weight Lifting Exercise Dataset," we applied machine learning techniques to classify five possible movement categories (A, B, C, D, and E). This analysis evaluates model accuracy, applies cross-validation for robust results, and generates predictions for a test set.


### Download and Load the Data

```{r}
# Load required libraries
library(dplyr)

# Download and read training data
train_url <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"
test_url <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"
train_data <- read.csv(train_url, na.strings = c("", "NA"))
test_data <- read.csv(test_url, na.strings = c("", "NA"))
```


### Data Preprocessing

The dataset includes accelerometer readings from the belt, forearm, arm, and dumbbell of six participants performing barbell lifts. The original dataset contained missing values and irrelevant variables, which were addressed as follows:

1. Data Cleaning

- Removed columns with more than 50% missing data.
- Dropped irrelevant features like user_name, timestamps, and window identifiers.
- Ensured the target variable classe was a factor.

```{r}
# Remove columns with NA values
train_data <- train_data[, colSums(is.na(train_data)) == 0]

# Drop irrelevant columns
train_data <- train_data %>%
  select(-c(X, user_name, raw_timestamp_part_1, raw_timestamp_part_2, cvtd_timestamp, new_window, num_window))

# Ensure `classe` is a factor
train_data$classe <- factor(train_data$classe)
```

2. Train-Test Split: The training data was split into 70% for training and 30% for validation using caret::createDataPartition.


### Model Development

We trained a Random Forest model due to its robustness against noisy and high-dimensional data, as present in this dataset.

#### Cross-Validation

To prevent overfitting and ensure generalizability, 5-fold cross-validation was employed. The training process used the following parameters:

- Method: Random Forest
- Control: 5-fold cross-validation
- Metric: Accuracy

```{r}
library(caret)

set.seed(123)  # For reproducibility
train_index <- createDataPartition(train_data$classe, p = 0.7, list = FALSE)
training <- train_data[train_index, ]
validation <- train_data[-train_index, ]

```

#### Model Selection

The Random Forest model was chosen for its ability to handle multicollinearity, its high performance with classification tasks, and feature importance rankings.



### Train the Model

Use the caret package to train a Random Forest model with cross-validation:

```{r}
set.seed(123)
control <- trainControl(method = "cv", number = 5)  # 5-fold cross-validation
rf_model <- train(classe ~ ., data = training, method = "rf", trControl = control)
```


### Results

#### Validation Performance

The model achieved excellent performance on the validation set, with high accuracy across all classe categories.

```{r}
# Make predictions
validation_predictions <- predict(rf_model, validation)

# Confusion matrix
confusionMatrix(validation_predictions, validation$classe)
```
#### Accuracy: 99.3%

The confusion matrix shows the model accurately classifies almost all instances, with very few misclassifications.

#### Feature Importance

The Random Forest model ranked features by importance, revealing the accelerometer signals from the belt and dumbbell as key predictors. Visualizing feature importance can help in future feature selection and optimization.


### Test Set Predictions

The model was applied to the 20 test cases provided in the dataset. Predictions were made using the trained Random Forest model.

```{r}
# Predict for the test set
test_predictions <- predict(rf_model, test_data)

# Save predictions to a CSV file
write.csv(test_predictions, "predictions.csv", row.names = FALSE)
```

The predictions were exported in a format suitable for submission to the Course Project Prediction Quiz.


### Conclusion

This analysis demonstrates the efficacy of Random Forest for predicting exercise manners with high accuracy. The cross-validation process ensured reliable generalization to unseen data, as evidenced by the strong performance on the validation set. Predictions for the test cases were successfully generated.

#### Future Improvements

- Hyperparameter Tuning: Optimize the Random Forest model further by exploring grid search or Bayesian optimization.
- Feature Engineering: Explore additional derived features (e.g., rolling averages or variance) to enhance predictions.
- Explore Alternative Models: Compare Random Forest with other models such as Gradient Boosting Machines or Neural Networks.